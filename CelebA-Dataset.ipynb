{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:00.418260Z",
     "start_time": "2017-08-31T00:00:00.162887Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:00.450083Z",
     "start_time": "2017-08-31T00:00:00.447214Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir_if_not_exists(path):\n",
    "    '''\n",
    "    Create directory if it does not exist.\n",
    "        path:           Path of directory.\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:00.672054Z",
     "start_time": "2017-08-31T00:00:00.662779Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images_name_in_directory(path):\n",
    "    '''\n",
    "    Get file name of all images recursively in directory filtered by extension list.\n",
    "        path: Path of directory contains images.\n",
    "    Return file name of images in selected directory.\n",
    "    '''\n",
    "    images_name_in_directory = []\n",
    "    image_extensions = ['.png', '.jpg']\n",
    "    \n",
    "    for root_path, directory_names, file_names in os.walk(path):\n",
    "        for file_name in file_names:\n",
    "            lower_file_name = file_name.lower()\n",
    "            if any(map(lambda image_extension: \n",
    "                       lower_file_name.endswith(image_extension), \n",
    "                       image_extensions)):\n",
    "                images_name_in_directory.append(file_name)\n",
    "\n",
    "    return images_name_in_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:00.883867Z",
     "start_time": "2017-08-31T00:00:00.880537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_unnormalized_image(path):\n",
    "    '''\n",
    "    Load a RGB image and do not normalize. Each intensity value is from \n",
    "    0 to 255 and then it is converted into 32-bit float.\n",
    "        path: Path of image file.\n",
    "    Return image array.\n",
    "    '''\n",
    "    return scipy.misc.imread(path, mode = 'RGB').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:01.177790Z",
     "start_time": "2017-08-31T00:00:01.171737Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_unnormalized_image(image, path):\n",
    "    '''\n",
    "    Merge multiple unnormalized images into one and save it.\n",
    "        image:  Unnormalized image array. The intensity values range\n",
    "                from 0 to 255. Format: [height, width, channels]\n",
    "        path:   Path of image.\n",
    "    '''\n",
    "    # Attention: Here we should not use the following way to save image.\n",
    "    #     scipy.misc.imsave(path, image)\n",
    "    # Because it automatically scale the intensity value in merged_image\n",
    "    # from [min(image), max(image)] to [0, 255]. It should be\n",
    "    # the reason behind the issue reported by Kwonjoon Lee, which states \n",
    "    # the intensity value in demo in ICL/IGM paper is much near 0 or 255.\n",
    "    scipy.misc.toimage(arr = image, cmin = 0, cmax = 255).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:01.641755Z",
     "start_time": "2017-08-31T00:00:01.633935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_crop(image, cropped_height, cropped_width):\n",
    "    '''\n",
    "    Crop the center part of image.\n",
    "        image:          Unnormalized image array. The intensity values range\n",
    "                        from 0 to 255. Format: [height, width, channels]\n",
    "        cropped_height: Height of cropped part.\n",
    "        cropped_width:  Width of cropped part.\n",
    "    Return array of cropped part.\n",
    "    '''\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    \n",
    "    cropped_in_image_height = int(round((image_height - cropped_height) / 2.))\n",
    "    cropped_in_image_width = int(round((image_width - cropped_width) / 2.))\n",
    "    \n",
    "    cropped = image[cropped_in_image_height : cropped_in_image_height + cropped_height, \n",
    "                    cropped_in_image_width : cropped_in_image_width + cropped_width]\n",
    "    \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:02.098773Z",
     "start_time": "2017-08-31T00:00:02.095570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(image, resized_height, resized_width):\n",
    "    '''\n",
    "    Resize the image.\n",
    "        image:          Image array.\n",
    "        resized_height: Height of resized part.\n",
    "        resized_width:  Width of resized part.\n",
    "    Return array of resized part.\n",
    "    '''\n",
    "    return scipy.misc.imresize(image, [resized_height, resized_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:02.565293Z",
     "start_time": "2017-08-31T00:00:02.559982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create directories.\n",
    "mkdir_if_not_exists('./dataset')\n",
    "mkdir_if_not_exists('./dataset/celeba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:16.702704Z",
     "start_time": "2017-08-31T00:00:03.081994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-08-30 17:00:03--  https://cseweb.ucsd.edu/~weijian/static/celeba/img_align_celeba.zip\n",
      "Resolving cseweb.ucsd.edu (cseweb.ucsd.edu)... 132.239.8.30\n",
      "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1443490838 (1.3G) [application/zip]\n",
      "Saving to: ‘./dataset/celeba/img_align_celeba.zip’\n",
      "\n",
      "100%[====================================>] 1,443,490,838  109MB/s   in 13s    \n",
      "\n",
      "2017-08-30 17:00:16 (102 MB/s) - ‘./dataset/celeba/img_align_celeba.zip’ saved [1443490838/1443490838]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download CelebA dataset.\n",
    "!wget -P ./dataset/celeba https://cseweb.ucsd.edu/~weijian/static/celeba/img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:00:28.968206Z",
     "start_time": "2017-08-31T00:00:16.705973Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract images.\n",
    "!unzip -q ./dataset/celeba/img_align_celeba.zip -d ./dataset/celeba\n",
    "!mv ./dataset/celeba/img_align_celeba ./dataset/celeba/original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:05:34.375902Z",
     "start_time": "2017-08-31T00:00:28.969934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping and resizing 0 images...\n",
      "Cropping and resizing 1000 images...\n",
      "Cropping and resizing 2000 images...\n",
      "Cropping and resizing 3000 images...\n",
      "Cropping and resizing 4000 images...\n",
      "Cropping and resizing 5000 images...\n",
      "Cropping and resizing 6000 images...\n",
      "Cropping and resizing 7000 images...\n",
      "Cropping and resizing 8000 images...\n",
      "Cropping and resizing 9000 images...\n",
      "Cropping and resizing 10000 images...\n",
      "Cropping and resizing 11000 images...\n",
      "Cropping and resizing 12000 images...\n",
      "Cropping and resizing 13000 images...\n",
      "Cropping and resizing 14000 images...\n",
      "Cropping and resizing 15000 images...\n",
      "Cropping and resizing 16000 images...\n",
      "Cropping and resizing 17000 images...\n",
      "Cropping and resizing 18000 images...\n",
      "Cropping and resizing 19000 images...\n",
      "Cropping and resizing 20000 images...\n",
      "Cropping and resizing 21000 images...\n",
      "Cropping and resizing 22000 images...\n",
      "Cropping and resizing 23000 images...\n",
      "Cropping and resizing 24000 images...\n",
      "Cropping and resizing 25000 images...\n",
      "Cropping and resizing 26000 images...\n",
      "Cropping and resizing 27000 images...\n",
      "Cropping and resizing 28000 images...\n",
      "Cropping and resizing 29000 images...\n",
      "Cropping and resizing 30000 images...\n",
      "Cropping and resizing 31000 images...\n",
      "Cropping and resizing 32000 images...\n",
      "Cropping and resizing 33000 images...\n",
      "Cropping and resizing 34000 images...\n",
      "Cropping and resizing 35000 images...\n",
      "Cropping and resizing 36000 images...\n",
      "Cropping and resizing 37000 images...\n",
      "Cropping and resizing 38000 images...\n",
      "Cropping and resizing 39000 images...\n",
      "Cropping and resizing 40000 images...\n",
      "Cropping and resizing 41000 images...\n",
      "Cropping and resizing 42000 images...\n",
      "Cropping and resizing 43000 images...\n",
      "Cropping and resizing 44000 images...\n",
      "Cropping and resizing 45000 images...\n",
      "Cropping and resizing 46000 images...\n",
      "Cropping and resizing 47000 images...\n",
      "Cropping and resizing 48000 images...\n",
      "Cropping and resizing 49000 images...\n",
      "Cropping and resizing 50000 images...\n",
      "Cropping and resizing 51000 images...\n",
      "Cropping and resizing 52000 images...\n",
      "Cropping and resizing 53000 images...\n",
      "Cropping and resizing 54000 images...\n",
      "Cropping and resizing 55000 images...\n",
      "Cropping and resizing 56000 images...\n",
      "Cropping and resizing 57000 images...\n",
      "Cropping and resizing 58000 images...\n",
      "Cropping and resizing 59000 images...\n",
      "Cropping and resizing 60000 images...\n",
      "Cropping and resizing 61000 images...\n",
      "Cropping and resizing 62000 images...\n",
      "Cropping and resizing 63000 images...\n",
      "Cropping and resizing 64000 images...\n",
      "Cropping and resizing 65000 images...\n",
      "Cropping and resizing 66000 images...\n",
      "Cropping and resizing 67000 images...\n",
      "Cropping and resizing 68000 images...\n",
      "Cropping and resizing 69000 images...\n",
      "Cropping and resizing 70000 images...\n",
      "Cropping and resizing 71000 images...\n",
      "Cropping and resizing 72000 images...\n",
      "Cropping and resizing 73000 images...\n",
      "Cropping and resizing 74000 images...\n",
      "Cropping and resizing 75000 images...\n",
      "Cropping and resizing 76000 images...\n",
      "Cropping and resizing 77000 images...\n",
      "Cropping and resizing 78000 images...\n",
      "Cropping and resizing 79000 images...\n",
      "Cropping and resizing 80000 images...\n",
      "Cropping and resizing 81000 images...\n",
      "Cropping and resizing 82000 images...\n",
      "Cropping and resizing 83000 images...\n",
      "Cropping and resizing 84000 images...\n",
      "Cropping and resizing 85000 images...\n",
      "Cropping and resizing 86000 images...\n",
      "Cropping and resizing 87000 images...\n",
      "Cropping and resizing 88000 images...\n",
      "Cropping and resizing 89000 images...\n",
      "Cropping and resizing 90000 images...\n",
      "Cropping and resizing 91000 images...\n",
      "Cropping and resizing 92000 images...\n",
      "Cropping and resizing 93000 images...\n",
      "Cropping and resizing 94000 images...\n",
      "Cropping and resizing 95000 images...\n",
      "Cropping and resizing 96000 images...\n",
      "Cropping and resizing 97000 images...\n",
      "Cropping and resizing 98000 images...\n",
      "Cropping and resizing 99000 images...\n",
      "Cropping and resizing 100000 images...\n",
      "Cropping and resizing 101000 images...\n",
      "Cropping and resizing 102000 images...\n",
      "Cropping and resizing 103000 images...\n",
      "Cropping and resizing 104000 images...\n",
      "Cropping and resizing 105000 images...\n",
      "Cropping and resizing 106000 images...\n",
      "Cropping and resizing 107000 images...\n",
      "Cropping and resizing 108000 images...\n",
      "Cropping and resizing 109000 images...\n",
      "Cropping and resizing 110000 images...\n",
      "Cropping and resizing 111000 images...\n",
      "Cropping and resizing 112000 images...\n",
      "Cropping and resizing 113000 images...\n",
      "Cropping and resizing 114000 images...\n",
      "Cropping and resizing 115000 images...\n",
      "Cropping and resizing 116000 images...\n",
      "Cropping and resizing 117000 images...\n",
      "Cropping and resizing 118000 images...\n",
      "Cropping and resizing 119000 images...\n",
      "Cropping and resizing 120000 images...\n",
      "Cropping and resizing 121000 images...\n",
      "Cropping and resizing 122000 images...\n",
      "Cropping and resizing 123000 images...\n",
      "Cropping and resizing 124000 images...\n",
      "Cropping and resizing 125000 images...\n",
      "Cropping and resizing 126000 images...\n",
      "Cropping and resizing 127000 images...\n",
      "Cropping and resizing 128000 images...\n",
      "Cropping and resizing 129000 images...\n",
      "Cropping and resizing 130000 images...\n",
      "Cropping and resizing 131000 images...\n",
      "Cropping and resizing 132000 images...\n",
      "Cropping and resizing 133000 images...\n",
      "Cropping and resizing 134000 images...\n",
      "Cropping and resizing 135000 images...\n",
      "Cropping and resizing 136000 images...\n",
      "Cropping and resizing 137000 images...\n",
      "Cropping and resizing 138000 images...\n",
      "Cropping and resizing 139000 images...\n",
      "Cropping and resizing 140000 images...\n",
      "Cropping and resizing 141000 images...\n",
      "Cropping and resizing 142000 images...\n",
      "Cropping and resizing 143000 images...\n",
      "Cropping and resizing 144000 images...\n",
      "Cropping and resizing 145000 images...\n",
      "Cropping and resizing 146000 images...\n",
      "Cropping and resizing 147000 images...\n",
      "Cropping and resizing 148000 images...\n",
      "Cropping and resizing 149000 images...\n",
      "Cropping and resizing 150000 images...\n",
      "Cropping and resizing 151000 images...\n",
      "Cropping and resizing 152000 images...\n",
      "Cropping and resizing 153000 images...\n",
      "Cropping and resizing 154000 images...\n",
      "Cropping and resizing 155000 images...\n",
      "Cropping and resizing 156000 images...\n",
      "Cropping and resizing 157000 images...\n",
      "Cropping and resizing 158000 images...\n",
      "Cropping and resizing 159000 images...\n",
      "Cropping and resizing 160000 images...\n",
      "Cropping and resizing 161000 images...\n",
      "Cropping and resizing 162000 images...\n",
      "Cropping and resizing 163000 images...\n",
      "Cropping and resizing 164000 images...\n",
      "Cropping and resizing 165000 images...\n",
      "Cropping and resizing 166000 images...\n",
      "Cropping and resizing 167000 images...\n",
      "Cropping and resizing 168000 images...\n",
      "Cropping and resizing 169000 images...\n",
      "Cropping and resizing 170000 images...\n",
      "Cropping and resizing 171000 images...\n",
      "Cropping and resizing 172000 images...\n",
      "Cropping and resizing 173000 images...\n",
      "Cropping and resizing 174000 images...\n",
      "Cropping and resizing 175000 images...\n",
      "Cropping and resizing 176000 images...\n",
      "Cropping and resizing 177000 images...\n",
      "Cropping and resizing 178000 images...\n",
      "Cropping and resizing 179000 images...\n",
      "Cropping and resizing 180000 images...\n",
      "Cropping and resizing 181000 images...\n",
      "Cropping and resizing 182000 images...\n",
      "Cropping and resizing 183000 images...\n",
      "Cropping and resizing 184000 images...\n",
      "Cropping and resizing 185000 images...\n",
      "Cropping and resizing 186000 images...\n",
      "Cropping and resizing 187000 images...\n",
      "Cropping and resizing 188000 images...\n",
      "Cropping and resizing 189000 images...\n",
      "Cropping and resizing 190000 images...\n",
      "Cropping and resizing 191000 images...\n",
      "Cropping and resizing 192000 images...\n",
      "Cropping and resizing 193000 images...\n",
      "Cropping and resizing 194000 images...\n",
      "Cropping and resizing 195000 images...\n",
      "Cropping and resizing 196000 images...\n",
      "Cropping and resizing 197000 images...\n",
      "Cropping and resizing 198000 images...\n",
      "Cropping and resizing 199000 images...\n",
      "Cropping and resizing 200000 images...\n",
      "Cropping and resizing 201000 images...\n",
      "Cropping and resizing 202000 images...\n"
     ]
    }
   ],
   "source": [
    "# Crop and resize images.\n",
    "mkdir_if_not_exists('./dataset/celeba/cropped')\n",
    "original_images_name = get_images_name_in_directory('./dataset/celeba/original/')\n",
    "for (i, original_image_name) in enumerate(original_images_name):\n",
    "    original_image_path = os.path.join('./dataset/celeba/original', original_image_name)\n",
    "    original_image = load_unnormalized_image(original_image_path)\n",
    "    cropped_image = resize(center_crop(image = original_image, \n",
    "                                       cropped_height = 108, \n",
    "                                       cropped_width = 108),\n",
    "                           resized_height = 64,\n",
    "                           resized_width = 64)\n",
    "    cropped_image_path = os.path.join('./dataset/celeba/cropped', original_image_name)\n",
    "    save_unnormalized_image(cropped_image, cropped_image_path)\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Cropping and resizing {} images...\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
